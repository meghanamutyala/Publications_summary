{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuxJ/UXKnhOx+mUHT6B06R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghanamutyala/Publications_summary/blob/main/publicationSummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69W2lZSssvqt",
        "outputId": "d7e17a97-3607-4192-83b7-734b62db10fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scholarly in /usr/local/lib/python3.10/dist-packages (1.7.11)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.12.3)\n",
            "Requirement already satisfied: bibtexparser in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.4.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.2.14)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.5.1)\n",
            "Requirement already satisfied: free-proxy in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.1.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from scholarly) (0.27.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.0.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from scholarly) (2.32.3)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.24.0)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.10/dist-packages (from scholarly) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from scholarly) (4.12.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->scholarly) (2.9.0.20240906)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->scholarly) (2.6)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from bibtexparser->scholarly) (3.1.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scholarly) (1.16.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->scholarly) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->scholarly) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (1.26.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->scholarly) (1.7.1)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly) (0.11.1)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly) (1.8.0)\n",
            "Requirement already satisfied: sphinx<8,>=5 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.21 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (0.18.1)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->scholarly) (4.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.16.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (1.3.0.post0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->scholarly) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install scholarly pandas python-docx openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scholarly import scholarly\n",
        "from datetime import datetime\n",
        "\n",
        "def fetch_publications(faculty_name):\n",
        "    search_query = scholarly.search_author(faculty_name)\n",
        "    author = next(search_query)\n",
        "\n",
        "    # Fill in the publication details\n",
        "    scholarly.fill(author, sections=['publications'])\n",
        "    publications = author['publications']\n",
        "\n",
        "    # Extract relevant data: title, year, venue\n",
        "    data = []\n",
        "    for pub in publications:\n",
        "        pub_data = {\n",
        "            'title': pub['bib']['title'],\n",
        "            'year': pub['bib'].get('pub_year', 'N/A'),\n",
        "\n",
        "        }\n",
        "        data.append(pub_data)\n",
        "\n",
        "    # Convert the data to a DataFrame for easier handling\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "faculty_name = \"Michel Foucault\"  # Replace with a real faculty name\n",
        "publication_data = fetch_publications(faculty_name)\n",
        "print(publication_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUNzncfuveuw",
        "outputId": "3bd705f3-a02d-405a-a88a-e05dc1ae4588"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bs4/builder/__init__.py:314: RuntimeWarning: coroutine 'fetch_dblp_publications' was never awaited\n",
            "  for attr in list(attrs.keys()):\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  title  year\n",
            "0                                 Discipline and punish  2023\n",
            "1                                       Power/knowledge  2020\n",
            "2             The history of sexuality: An introduction  1990\n",
            "3                              Archaeology of knowledge  2013\n",
            "4                                 Microfísica del poder  1978\n",
            "...                                                 ...   ...\n",
            "2275                 HEBE VESSURI MARÍA VICTORIA CANINC   N/A\n",
            "2276      Michel Foucault: généalogie d'un intellectuel   N/A\n",
            "2277  Policía, Gobierno y Racionalidad Incursiones a...   N/A\n",
            "2278  Foucault e o Direito Penal: Vigiar e Punir War...   N/A\n",
            "2279  “A Fish in Water”: Michel Foucault and Histori...   N/A\n",
            "\n",
            "[2280 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyppeteer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RihWIjUESagq",
        "outputId": "26186de0-9bf7-4d1e-ba3d-b81f17a065bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyppeteer in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (2024.8.30)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (8.5.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (11.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (4.66.5)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (1.26.20)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (10.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages if not already installed\n",
        "!pip install nest_asyncio aiohttp\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e6c6R9PR7EI",
        "outputId": "ac4d09a5-90ba-401d-bb65-d14ae096fa12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Apply the nest_asyncio patch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the asynchronous function to fetch publications\n",
        "async def fetch_dblp_publications(faculty_name):\n",
        "    url = f\"https://dblp.org/search/publ/api?q={faculty_name.replace(' ', '+')}&h=1000\"  # Example URL\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            if response.status == 200:\n",
        "                html = await response.text()\n",
        "                soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "                # Extract publication data from the soup object\n",
        "                publications = []\n",
        "                for entry in soup.find_all('hit'):\n",
        "                    title = entry.find('title').text\n",
        "                    year = entry.find('year').text\n",
        "                    publications.append({'Title': title, 'Year': year})\n",
        "\n",
        "                return pd.DataFrame(publications)\n",
        "            else:\n",
        "                print(f\"Failed to retrieve data: {response.status}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "# Define the main function to run the asynchronous code\n",
        "async def main():\n",
        "    df = await fetch_dblp_publications('Michel Foucault')\n",
        "    print(df)\n",
        "\n",
        "# Run the main function\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV-fGTAOS7SN",
        "outputId": "ea45c064-ad4c-41ad-94e2-74ac7870855c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  Year\n",
            "0  SPad: a bimanual interaction technique for pro...  2014\n",
            "1  Computer Gameplay and the Aesthetic Practices ...  2018\n",
            "2  The library as heterotopia: Michel Foucault an...  2015\n",
            "3  Exploring informed virtual sites through Miche...  2009\n",
            "4  New design and prototyping methods are neede i...  1996\n",
            "5  \"Technologies of the Self\": Michel Foucault On...  1995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  k = self.parse_starttag(i)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcx5uQWpTJ3q",
        "outputId": "21c99481-c946-4384-bbd2-c751082dabfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Apply the nest_asyncio patch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the asynchronous function to fetch publications\n",
        "async def fetch_dblp_publications(faculty_name):\n",
        "    url = f\"https://dblp.org/search/publ/api?q={faculty_name.replace(' ', '+')}&h=1000\"  # Example URL\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            if response.status == 200:\n",
        "                xml = await response.text()\n",
        "                soup = BeautifulSoup(xml, 'lxml-xml')  # Use lxml-xml for XML parsing\n",
        "\n",
        "                # Extract publication data from the soup object\n",
        "                publications = []\n",
        "                for entry in soup.find_all('hit'):\n",
        "                    title = entry.find('title').text\n",
        "                    year = entry.find('year').text\n",
        "                    publications.append({'title': title, 'year': year, \"academic_database\": \"DBLP\"})\n",
        "\n",
        "                return pd.DataFrame(publications)\n",
        "            else:\n",
        "                print(f\"Failed to retrieve data: {response.status}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "# Define the main function to run the asynchronous code\n",
        "async def main():\n",
        "    dblp_data = await fetch_dblp_publications('Michel Foucault')\n",
        "    print(dblp_data)\n",
        "\n",
        "# Run the main function\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzBH6Er7TMC3",
        "outputId": "13e63048-7239-4d56-ba90-7d61bc0abb46"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  year academic_database\n",
            "0  SPad: a bimanual interaction technique for pro...  2014              DBLP\n",
            "1  Computer Gameplay and the Aesthetic Practices ...  2018              DBLP\n",
            "2  The library as heterotopia: Michel Foucault an...  2015              DBLP\n",
            "3  Exploring informed virtual sites through Miche...  2009              DBLP\n",
            "4  New design and prototyping methods are neede i...  1996              DBLP\n",
            "5  \"Technologies of the Self\": Michel Foucault On...  1995              DBLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scholarly import scholarly\n",
        "\n",
        "def fetch_publications(faculty_name):\n",
        "    search_query = scholarly.search_author(faculty_name)\n",
        "    author = next(search_query)\n",
        "\n",
        "    # Fill in the publication details\n",
        "    scholarly.fill(author, sections=['publications'])\n",
        "    publications = author['publications']\n",
        "\n",
        "    # Extract relevant data: title, year\n",
        "    data = []\n",
        "    for pub in publications:\n",
        "        pub_data = {\n",
        "            'title': pub['bib'].get('title', 'No Title'),\n",
        "            'year': pub['bib'].get('pub_year', 'N/A'),\n",
        "            \"academic_database\": \"Google Scholar\"\n",
        "\n",
        "        }\n",
        "        data.append(pub_data)\n",
        "\n",
        "    # Convert the data to a DataFrame for easier handling\n",
        "    df = pd.DataFrame(data)\n",
        "    print(list(df.columns))\n",
        "\n",
        "    # Optional: Clean up the DataFrame to remove unnecessary rows or fill in missing data\n",
        "    df = df[df['year'] != 'N/A']  # Remove rows with 'N/A' years if desired\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "faculty_name = \"Michel Foucault\"  # Replace with a real faculty name\n",
        "publication_data = fetch_publications(faculty_name)\n",
        "\n",
        "print(publication_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fozzL6bqUH9J",
        "outputId": "8f4f3d1f-dff4-4ec7-9207-61fbfdd7f3a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['title', 'year', 'academic_database']\n",
            "                                                  title  year  \\\n",
            "0                                 Discipline and punish  2023   \n",
            "1                                       Power/knowledge  2020   \n",
            "2             The history of sexuality: An introduction  1990   \n",
            "3                              Archaeology of knowledge  2013   \n",
            "4                                 Microfísica del poder  1978   \n",
            "...                                                 ...   ...   \n",
            "2123                 FOUCAULT EST VRAIMENT EXCEPTIONNEL  1962   \n",
            "2124  Folie et déraison: histoire de l'expérience de...  1961   \n",
            "2125  Folie et déraison: Histoire de la folie à l'âg...  1961   \n",
            "2126  Le Cycle de la structure,«Bibliothèque neuro-p...  1958   \n",
            "2127          Psychologie scolaire (Plaidoyer pour la-)  1925   \n",
            "\n",
            "     academic_database  \n",
            "0       Google Scholar  \n",
            "1       Google Scholar  \n",
            "2       Google Scholar  \n",
            "3       Google Scholar  \n",
            "4       Google Scholar  \n",
            "...                ...  \n",
            "2123    Google Scholar  \n",
            "2124    Google Scholar  \n",
            "2125    Google Scholar  \n",
            "2126    Google Scholar  \n",
            "2127    Google Scholar  \n",
            "\n",
            "[2102 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from scholarly import scholarly\n",
        "\n",
        "# Apply the nest_asyncio patch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the asynchronous function to fetch DBLP publications\n",
        "async def fetch_dblp_publications(faculty_name):\n",
        "    url = f\"https://dblp.org/search/publ/api?q={faculty_name.replace(' ', '+')}&h=1000\"  # Example URL\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            if response.status == 200:\n",
        "                xml = await response.text()\n",
        "                soup = BeautifulSoup(xml, 'lxml-xml')  # Use lxml-xml for XML parsing\n",
        "\n",
        "                # Extract publication data from the soup object\n",
        "                publications = []\n",
        "                for entry in soup.find_all('hit'):\n",
        "                    title = entry.find('title').text\n",
        "                    year = entry.find('year').text\n",
        "                    publications.append({'title': title, 'year': year, \"academic_database\": \"DBLP\"})\n",
        "\n",
        "                return pd.DataFrame(publications)\n",
        "            else:\n",
        "                print(f\"Failed to retrieve data: {response.status}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "# Define the function to fetch Google Scholar publications\n",
        "def fetch_google_scholar_publications(faculty_name):\n",
        "    search_query = scholarly.search_author(faculty_name)\n",
        "    author = next(search_query)\n",
        "\n",
        "    # Fill in the publication details\n",
        "    scholarly.fill(author, sections=['publications'])\n",
        "    publications = author['publications']\n",
        "\n",
        "    # Extract relevant data: title, year\n",
        "    data = []\n",
        "    for pub in publications:\n",
        "        pub_data = {\n",
        "            'title': pub['bib'].get('title', 'No Title'),\n",
        "            'year': pub['bib'].get('pub_year', 'N/A'),\n",
        "            \"academic_database\": \"Google Scholar\"\n",
        "        }\n",
        "        data.append(pub_data)\n",
        "\n",
        "    # Convert the data to a DataFrame for easier handling\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Optional: Clean up the DataFrame to remove unnecessary rows or fill in missing data\n",
        "    df = df[df['year'] != 'N/A']  # Remove rows with 'N/A' years if desired\n",
        "    return df\n",
        "\n",
        "# Define the main function to fetch data from both sources and combine them\n",
        "async def main():\n",
        "    faculty_name = \"Michel Foucault\"  # Replace with a real faculty name\n",
        "\n",
        "    # Fetch DBLP data\n",
        "    dblp_data = await fetch_dblp_publications(faculty_name)\n",
        "\n",
        "    # Fetch Google Scholar data\n",
        "    google_scholar_data = fetch_google_scholar_publications(faculty_name)\n",
        "\n",
        "    # Combine both DataFrames\n",
        "    combined_df = pd.concat([dblp_data, google_scholar_data], ignore_index=True)\n",
        "\n",
        "    # Convert the 'year' column to numeric, errors='coerce' will turn invalid parsing into NaN\n",
        "    combined_df['year'] = pd.to_numeric(combined_df['year'], errors='coerce')\n",
        "\n",
        "    # Sort the combined DataFrame by year in descending order\n",
        "    start_year = int(input(\"Enter the start year (e.g., 2003): \"))\n",
        "    end_year = int(input(\"Enter the end year (e.g., 2023): \"))\n",
        "\n",
        "    # Filter the DataFrame based on the selected year range\n",
        "    filtered_df = combined_df[(combined_df['year'] >= start_year) & (combined_df['year'] <= end_year)]\n",
        "\n",
        "    # Sort the filtered DataFrame by year in descending order\n",
        "    sorted_filtered_df = filtered_df.sort_values(by='year', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Print the sorted and filtered DataFrame\n",
        "    print(sorted_filtered_df)\n",
        "\n",
        "# Run the main function\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q0IIM89ak5q",
        "outputId": "41d78c91-ce3a-44c4-cac6-cec054458a60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the start year (e.g., 2003): 1990\n",
            "Enter the end year (e.g., 2023): 2014\n",
            "                                                  title  year  \\\n",
            "0     SPad: a bimanual interaction technique for pro...  2014   \n",
            "1                   Droit de mort et pouvoir sur la vie  2014   \n",
            "2                Histoire de la folie à l'âge classique  2014   \n",
            "3                            Enlightenment thinking 109  2014   \n",
            "4     Bezpieczeństwo, terytorium, populacja: wykłady...  2014   \n",
            "...                                                 ...   ...   \n",
            "1171             Predavanja:(kratak sadržaj): 1970-1982  1990   \n",
            "1172  The History of Sexuality: An Introduction (Vol...  1990   \n",
            "1173                           O pensamento do exterior  1990   \n",
            "1174                            translated by Hurley, R  1990   \n",
            "1175                         Resume de cours, 1970-1982  1990   \n",
            "\n",
            "     academic_database  \n",
            "0                 DBLP  \n",
            "1       Google Scholar  \n",
            "2       Google Scholar  \n",
            "3       Google Scholar  \n",
            "4       Google Scholar  \n",
            "...                ...  \n",
            "1171    Google Scholar  \n",
            "1172    Google Scholar  \n",
            "1173    Google Scholar  \n",
            "1174    Google Scholar  \n",
            "1175    Google Scholar  \n",
            "\n",
            "[1176 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv files\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from scholarly import scholarly\n",
        "\n",
        "# Apply the nest_asyncio patch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the asynchronous function to fetch DBLP publications\n",
        "async def fetch_dblp_publications(faculty_name):\n",
        "    url = f\"https://dblp.org/search/publ/api?q={faculty_name.replace(' ', '+')}&h=1000\"  # Example URL\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            if response.status == 200:\n",
        "                xml = await response.text()\n",
        "                soup = BeautifulSoup(xml, 'lxml-xml')  # Use lxml-xml for XML parsing\n",
        "\n",
        "                # Extract publication data from the soup object\n",
        "                publications = []\n",
        "                for entry in soup.find_all('hit'):\n",
        "                    title = entry.find('title').text\n",
        "                    year = entry.find('year').text\n",
        "                    publications.append({'title': title, 'year': year, \"academic_database\": \"DBLP\"})\n",
        "\n",
        "                return pd.DataFrame(publications)\n",
        "            else:\n",
        "                print(f\"Failed to retrieve data: {response.status}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "# Define the function to fetch Google Scholar publications\n",
        "def fetch_google_scholar_publications(faculty_name):\n",
        "    search_query = scholarly.search_author(faculty_name)\n",
        "    author = next(search_query)\n",
        "\n",
        "    # Fill in the publication details\n",
        "    scholarly.fill(author, sections=['publications'])\n",
        "    publications = author['publications']\n",
        "\n",
        "    # Extract relevant data: title, year\n",
        "    data = []\n",
        "    for pub in publications:\n",
        "        pub_data = {\n",
        "            'title': pub['bib'].get('title', 'No Title'),\n",
        "            'year': pub['bib'].get('pub_year', 'N/A'),\n",
        "            \"academic_database\": \"Google Scholar\"\n",
        "        }\n",
        "        data.append(pub_data)\n",
        "\n",
        "    # Convert the data to a DataFrame for easier handling\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Optional: Clean up the DataFrame to remove unnecessary rows or fill in missing data\n",
        "    df = df[df['year'] != 'N/A']  # Remove rows with 'N/A' years if desired\n",
        "    return df\n",
        "\n",
        "# Define the main function to fetch data from both sources and save them\n",
        "async def main():\n",
        "    faculty_name = input(\"Enter Author Name: \")  # Replace with a real faculty name\n",
        "\n",
        "    # Fetch DBLP data\n",
        "    dblp_data = await fetch_dblp_publications(faculty_name)\n",
        "    dblp_data.to_csv('dblp_publications.csv', index=False)\n",
        "\n",
        "    # Fetch Google Scholar data\n",
        "    google_scholar_data = fetch_google_scholar_publications(faculty_name)\n",
        "    google_scholar_data.to_csv('google_scholar_publications.csv', index=False)\n",
        "\n",
        "# Run the main function\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-EmZX5rdCBS",
        "outputId": "470f1d0c-0ae7-478f-b1ba-9e4e59f5552d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Author Name: Michel Foucault\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from docx import Document  # For exporting to Word\n",
        "import openpyxl  # For exporting to Excel\n",
        "\n",
        "# Define file paths\n",
        "dblp_file_path = 'dblp_publications.csv'\n",
        "google_scholar_file_path = 'google_scholar_publications.csv'\n",
        "\n",
        "# Function to load DataFrame from CSV if the file exists and is not empty\n",
        "def load_csv_if_exists(file_path):\n",
        "    try:\n",
        "        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
        "            return pd.read_csv(file_path)\n",
        "        else:\n",
        "            return pd.DataFrame()  # Return an empty DataFrame if file doesn't exist or is empty\n",
        "    except pd.errors.EmptyDataError:\n",
        "        return pd.DataFrame()  # Return an empty DataFrame if file is empty or unreadable\n",
        "\n",
        "# Load the saved DataFrames\n",
        "dblp_data = load_csv_if_exists(dblp_file_path)\n",
        "google_scholar_data = load_csv_if_exists(google_scholar_file_path)\n",
        "\n",
        "# Combine both DataFrames\n",
        "combined_df = pd.concat([dblp_data, google_scholar_data], ignore_index=True)\n",
        "\n",
        "# Convert the 'year' column to numeric, errors='coerce' will turn invalid parsing into NaN\n",
        "combined_df['year'] = pd.to_numeric(combined_df['year'], errors='coerce')\n",
        "\n",
        "# Get user input for start and end years\n",
        "start_year = int(input(\"Enter the start year (e.g., 2003): \"))\n",
        "end_year = int(input(\"Enter the end year (e.g., 2023): \"))\n",
        "\n",
        "# Filter the DataFrame based on the selected year range\n",
        "filtered_df = combined_df[(combined_df['year'] >= start_year) & (combined_df['year'] <= end_year)]\n",
        "\n",
        "# Sort the filtered DataFrame by year in descending order\n",
        "sorted_filtered_df = filtered_df.sort_values(by='year', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Print the sorted and filtered DataFrame\n",
        "print(sorted_filtered_df)\n",
        "\n",
        "# Ask the user whether they want to export as Excel or Word\n",
        "export_choice = input(\"Do you want to export the data to Excel or Word? (Enter 'excel' or 'word'): \").strip().lower()\n",
        "\n",
        "# Export to Excel\n",
        "if export_choice == 'excel':\n",
        "    excel_file_path = 'publications_filtered.xlsx'\n",
        "    sorted_filtered_df.to_excel(excel_file_path, index=False)\n",
        "    print(f\"Data exported to {excel_file_path}\")\n",
        "\n",
        "# Export to Word\n",
        "elif export_choice == 'word':\n",
        "    word_file_path = 'publications_filtered.docx'\n",
        "    doc = Document()\n",
        "\n",
        "    # Add a title to the document\n",
        "    doc.add_heading('Filtered Publications', 0)\n",
        "\n",
        "    # Add a table to the document\n",
        "    table = doc.add_table(rows=1, cols=len(sorted_filtered_df.columns))\n",
        "    hdr_cells = table.rows[0].cells\n",
        "\n",
        "    # Set the headers\n",
        "    for idx, column_name in enumerate(sorted_filtered_df.columns):\n",
        "        hdr_cells[idx].text = column_name\n",
        "\n",
        "    # Add the data rows\n",
        "    for index, row in sorted_filtered_df.iterrows():\n",
        "        row_cells = table.add_row().cells\n",
        "        for idx, cell_value in enumerate(row):\n",
        "            row_cells[idx].text = str(cell_value)\n",
        "\n",
        "    # Save the Word document\n",
        "    doc.save(word_file_path)\n",
        "    print(f\"Data exported to {word_file_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"Invalid input. Please enter 'excel' or 'word'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z73zPh4mgyek",
        "outputId": "e98caea8-9526-41b7-86d4-bc6fe75e978e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the start year (e.g., 2003): 2010\n",
            "Enter the end year (e.g., 2023): 2012\n",
            "                                                 title  year academic_database\n",
            "0                   On the Normal and the Pathological  2012    Google Scholar\n",
            "1                            Che cos' è l'illuminismo?  2012    Google Scholar\n",
            "2    Considerations on marxism, phenomenology and p...  2012    Google Scholar\n",
            "3                               Espacio, saber y poder  2012    Google Scholar\n",
            "4                               Dos suplícios às celas  2012    Google Scholar\n",
            "..                                                 ...   ...               ...\n",
            "117   L'etica della cura di sé come pratica di libertà  2010    Google Scholar\n",
            "118  Aula de 5 de janeiro de 1983 In: O governo de ...  2010    Google Scholar\n",
            "119                       Conversa com Michel Foucault  2010    Google Scholar\n",
            "120  Sobre o controle, a disciplina e a punição: no...  2010    Google Scholar\n",
            "121  Disciplina, biopoder e governo: contribuições ...  2010    Google Scholar\n",
            "\n",
            "[122 rows x 3 columns]\n",
            "Do you want to export the data to Excel or Word? (Enter 'excel' or 'word'): word\n",
            "Data exported to publications_filtered.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o24kG3fHTJfY"
      }
    }
  ]
}